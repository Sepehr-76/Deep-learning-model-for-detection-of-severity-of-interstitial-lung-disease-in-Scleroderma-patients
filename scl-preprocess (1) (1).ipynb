{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119967a0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-03T10:13:31.379272Z",
     "iopub.status.busy": "2024-04-03T10:13:31.378220Z",
     "iopub.status.idle": "2024-04-03T10:14:00.564856Z",
     "shell.execute_reply": "2024-04-03T10:14:00.563392Z"
    },
    "papermill": {
     "duration": 29.199194,
     "end_time": "2024-04-03T10:14:00.567690",
     "exception": false,
     "start_time": "2024-04-03T10:13:31.368496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install monai\n",
    "!pip install pynrrd\n",
    "!pip intall torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f884f549",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:14:00.584962Z",
     "iopub.status.busy": "2024-04-03T10:14:00.584237Z",
     "iopub.status.idle": "2024-04-03T10:14:53.819924Z",
     "shell.execute_reply": "2024-04-03T10:14:53.818778Z"
    },
    "papermill": {
     "duration": 53.247663,
     "end_time": "2024-04-03T10:14:53.822533",
     "exception": false,
     "start_time": "2024-04-03T10:14:00.574870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 10:14:43.901040: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-03 10:14:43.901157: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-03 10:14:44.095350: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from monai.data import Dataset\n",
    "from monai.data import DataLoader, decollate_batch\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    Activationsd,\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    Invertd,\n",
    "    LoadImaged,\n",
    "    LoadImage,\n",
    "    MapTransform,\n",
    "    NormalizeIntensityd,\n",
    "    NormalizeIntensity,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandScaleIntensityd,\n",
    "    RandShiftIntensityd,\n",
    "    RandSpatialCropd,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureChannelFirstd,\n",
    "    Resized,\n",
    "    Resize,\n",
    "    RandGaussianNoised,\n",
    "    RandBiasFieldd,\n",
    "    RandAdjustContrastd,\n",
    "    RandGaussianSmoothd,\n",
    "    RandRicianNoised,\n",
    "    CropForegroundd,\n",
    "    CropForeground,\n",
    "    RandRotated,\n",
    "    Rotate90d,\n",
    "    Flipd,\n",
    "    ScaleIntensityd,\n",
    "    CenterSpatialCropd,\n",
    "    KeepLargestConnectedComponent,\n",
    "    FillHoles\n",
    ")\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import convnext_tiny, swin_t\n",
    "from torchvision.models import efficientnet_v2_s\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics  import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "import nrrd\n",
    "from matplotlib.colors import ListedColormap\n",
    "green = ListedColormap(['k', 'g'])\n",
    "red = ListedColormap(['k', 'r'])\n",
    "from monai.losses import DiceFocalLoss\n",
    "from monai.metrics import DiceMetric\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06eb1c4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:14:53.838842Z",
     "iopub.status.busy": "2024-04-03T10:14:53.838024Z",
     "iopub.status.idle": "2024-04-03T10:14:53.854965Z",
     "shell.execute_reply": "2024-04-03T10:14:53.853943Z"
    },
    "papermill": {
     "duration": 0.02761,
     "end_time": "2024-04-03T10:14:53.857276",
     "exception": false,
     "start_time": "2024-04-03T10:14:53.829666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = os.listdir('/kaggle/input/scl-chest-ct/images')\n",
    "masks = os.listdir('/kaggle/input/scl-chest-ct/masks')\n",
    "dicts = []\n",
    "for i in range (1, 18):\n",
    "  dicts.append({\n",
    "      'image': f'/kaggle/input/scl-chest-ct/images/{i}.nii',\n",
    "      'label': f'/kaggle/input/scl-chest-ct/masks/{i}.nrrd'\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "564e94a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:14:53.873282Z",
     "iopub.status.busy": "2024-04-03T10:14:53.872913Z",
     "iopub.status.idle": "2024-04-03T10:14:53.879021Z",
     "shell.execute_reply": "2024-04-03T10:14:53.877714Z"
    },
    "papermill": {
     "duration": 0.016854,
     "end_time": "2024-04-03T10:14:53.881216",
     "exception": false,
     "start_time": "2024-04-03T10:14:53.864362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LoadNRRD(MapTransform): # load NRRD files (labels) and one-hot encode\n",
    "  def __call__(self, data):\n",
    "    for key in self.keys:\n",
    "      data[key] = torch.tensor(nrrd.read(data[key])[0])\n",
    "      # data[key] = torch.stack([torch.eq(data[key], i)  for i in range(1, 5)], dim=0).to(torch.float32) # for multiclass\n",
    "      # data[key] = torch.where(data[key] != 0, torch.tensor(1.0), torch.tensor(0.0)) # for lung segmentation\n",
    "#       data[key] = torch.stack([\n",
    "#           torch.where(data[key] == 1, torch.tensor(1.0), torch.tensor(0.0)),\n",
    "#           torch.where(data[key] > 1, torch.tensor(1.0), torch.tensor(0.0))\n",
    "#       ]).to(torch.float32)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f150494f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:14:53.897996Z",
     "iopub.status.busy": "2024-04-03T10:14:53.897057Z",
     "iopub.status.idle": "2024-04-03T10:14:53.904465Z",
     "shell.execute_reply": "2024-04-03T10:14:53.903648Z"
    },
    "papermill": {
     "duration": 0.017781,
     "end_time": "2024-04-03T10:14:53.906444",
     "exception": false,
     "start_time": "2024-04-03T10:14:53.888663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessing = Compose([\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        LoadNRRD(keys=['label']),\n",
    "        # AddChannelDim(keys=['image', 'label']), # for lung segmentation\n",
    "#         AddChannelDim(keys=['image']), # for multiclass\n",
    "#         CropForegroundd(keys=['image', 'label'], source_key='image'),\n",
    "#         Resized(keys=['image', 'label'], spatial_size=(128, 128, 32), mode=['trilinear', 'nearest-exact']), #expected efficientNetv2 size\n",
    "        # Rotate90d(k=3, keys=['image', 'label']),\n",
    "        # Rotate90d(k=1, keys=['image', 'label'], spatial_axes = (1, 2)),\n",
    "        # Rotate90d(k=3, keys=['image', 'label']),\n",
    "        # Rotate90d(k=2, keys=['image', 'label'], spatial_axes = (0, 2)),\n",
    "        # Flipd(keys=['image'], spatial_axis=1), #because jpeg files don't have correct orientation metadata\n",
    "        # ScaleIntensityd(keys='image', dtype=None), #for some reason slows preprocessing down\n",
    "#         NormalizeIntensityd(keys=\"image\"), #using mean and sd values from PyTorch doc\n",
    "        # RandScaleIntensityd(keys=\"image\", factors=0.1, prob=0.5),\n",
    "        # RandGaussianNoised(keys='image', prob=0.5, std=0.05),\n",
    "        # RandBiasFieldd(keys='image', degree=2),\n",
    "        # RandAdjustContrastd(keys='image', prob=0.3, gamma=(0.95, 1.05)),\n",
    "        # RandGaussianSmoothd(keys='image', prob=0.05, sigma_x=(0.95, 1.05), sigma_y=(0.95, 1.05)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37b0ac5",
   "metadata": {
    "papermill": {
     "duration": 0.006688,
     "end_time": "2024-04-03T10:14:53.920077",
     "exception": false,
     "start_time": "2024-04-03T10:14:53.913389",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Label shapes\n",
    "17: Nl, EsFib, FFib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ce682c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:14:53.936617Z",
     "iopub.status.busy": "2024-04-03T10:14:53.936206Z",
     "iopub.status.idle": "2024-04-03T10:14:54.085441Z",
     "shell.execute_reply": "2024-04-03T10:14:54.084235Z"
    },
    "papermill": {
     "duration": 0.161213,
     "end_time": "2024-04-03T10:14:54.088156",
     "exception": false,
     "start_time": "2024-04-03T10:14:53.926943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = dicts[-1]\n",
    "nr = nrrd.read(sub['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4121922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:14:54.104020Z",
     "iopub.status.busy": "2024-04-03T10:14:54.103634Z",
     "iopub.status.idle": "2024-04-03T10:14:54.109891Z",
     "shell.execute_reply": "2024-04-03T10:14:54.108739Z"
    },
    "papermill": {
     "duration": 0.016975,
     "end_time": "2024-04-03T10:14:54.112162",
     "exception": false,
     "start_time": "2024-04-03T10:14:54.095187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_names(sub):\n",
    "    nr = nrrd.read(sub['label'])\n",
    "    segment_names = {}\n",
    "    for key, value in nr[1].items():\n",
    "        if 'Segment' in key and '_Name' in key:\n",
    "            segment_names[key] = value\n",
    "    names = segment_names.values()\n",
    "    names = [x for x in names if x != '0']\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "366e56e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:14:54.127951Z",
     "iopub.status.busy": "2024-04-03T10:14:54.127580Z",
     "iopub.status.idle": "2024-04-03T10:15:16.686588Z",
     "shell.execute_reply": "2024-04-03T10:15:16.685620Z"
    },
    "papermill": {
     "duration": 22.570097,
     "end_time": "2024-04-03T10:15:16.689300",
     "exception": false,
     "start_time": "2024-04-03T10:14:54.119203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prep = preprocessing(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09eb5d4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:15:16.705868Z",
     "iopub.status.busy": "2024-04-03T10:15:16.705445Z",
     "iopub.status.idle": "2024-04-03T10:15:45.577342Z",
     "shell.execute_reply": "2024-04-03T10:15:45.575944Z"
    },
    "papermill": {
     "duration": 28.882856,
     "end_time": "2024-04-03T10:15:45.579825",
     "exception": false,
     "start_time": "2024-04-03T10:15:16.696969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': '/kaggle/input/scl-chest-ct/images/1.nii', 'label': '/kaggle/input/scl-chest-ct/masks/1.nrrd'}\n",
      "['Normal', 'GGO', 'Fibrosis', 'Fine fibrosis']\n",
      "tensor([0, 1, 3, 4], dtype=torch.uint8)\n",
      "torch.Size([512, 512, 198])\n",
      "**********\n",
      "{'image': '/kaggle/input/scl-chest-ct/images/2.nii', 'label': '/kaggle/input/scl-chest-ct/masks/2.nrrd'}\n",
      "['Normal', 'GGO', 'Fibrosis', 'Fine Fibrosis']\n",
      "tensor([0, 1, 2, 3], dtype=torch.int16)\n",
      "torch.Size([512, 512, 120])\n",
      "**********\n",
      "{'image': '/kaggle/input/scl-chest-ct/images/3.nii', 'label': '/kaggle/input/scl-chest-ct/masks/3.nrrd'}\n",
      "['Normal', 'GGO', 'Fibrosis', 'Fine fibrosis']\n",
      "tensor([0, 1, 3], dtype=torch.uint8)\n",
      "torch.Size([512, 512, 52])\n",
      "**********\n",
      "{'image': '/kaggle/input/scl-chest-ct/images/4.nii', 'label': '/kaggle/input/scl-chest-ct/masks/4.nrrd'}\n",
      "['Normal', 'GGO', 'Fibrosis', 'Fine fibrosis']\n",
      "tensor([0, 1, 2, 4], dtype=torch.uint8)\n",
      "torch.Size([512, 512, 70])\n",
      "**********\n",
      "{'image': '/kaggle/input/scl-chest-ct/images/5.nii', 'label': '/kaggle/input/scl-chest-ct/masks/5.nrrd'}\n",
      "['Normal', 'GGO', 'Fibrosis', 'Fine fibrosis']\n",
      "tensor([0, 1, 3], dtype=torch.uint8)\n",
      "torch.Size([512, 512, 153])\n",
      "**********\n",
      "{'image': '/kaggle/input/scl-chest-ct/images/6.nii', 'label': '/kaggle/input/scl-chest-ct/masks/6.nrrd'}\n",
      "['Normal', 'GGO', 'Fibrosis', 'Fine fibrosis']\n",
      "tensor([0, 1], dtype=torch.uint8)\n",
      "torch.Size([2, 512, 512, 103])\n",
      "**********\n",
      "{'image': '/kaggle/input/scl-chest-ct/images/7.nii', 'label': '/kaggle/input/scl-chest-ct/masks/7.nrrd'}\n",
      "['Normal', 'GGO', 'Fibrosis', 'Fine fibrosis']\n",
      "tensor([0, 1, 3, 4], dtype=torch.uint8)\n",
      "torch.Size([512, 512, 164])\n",
      "**********\n",
      "{'image': '/kaggle/input/scl-chest-ct/images/8.nii', 'label': '/kaggle/input/scl-chest-ct/masks/8.nrrd'}\n",
      "['Normal', 'GGO', 'Fibrosis', 'Fine fibrosis']\n",
      "tensor([0, 1, 2], dtype=torch.uint8)\n",
      "torch.Size([512, 512, 161])\n",
      "**********\n",
      "{'image': '/kaggle/input/scl-chest-ct/images/9.nii', 'label': '/kaggle/input/scl-chest-ct/masks/9.nrrd'}\n",
      "['Normal', 'Established fibrosis', 'Fine fibrosis/GGO']\n",
      "tensor([0, 1, 4], dtype=torch.uint8)\n",
      "torch.Size([512, 512, 145])\n",
      "**********\n",
      "{'image': '/kaggle/input/scl-chest-ct/images/10.nii', 'label': '/kaggle/input/scl-chest-ct/masks/10.nrrd'}\n",
      "['Normal', 'Established fibrosis', 'Fine fibrosis/GGO']\n",
      "tensor([0, 1, 4], dtype=torch.uint8)\n",
      "torch.Size([512, 512, 145])\n",
      "**********\n",
      "{'image': '/kaggle/input/scl-chest-ct/images/11.nii', 'label': '/kaggle/input/scl-chest-ct/masks/11.nrrd'}\n",
      "['Normal', 'Established fibrosis', 'Fine fibrosis/GGO']\n",
      "tensor([0, 1, 3, 4], dtype=torch.uint8)\n",
      "torch.Size([512, 512, 167])\n",
      "**********\n",
      "{'image': '/kaggle/input/scl-chest-ct/images/12.nii', 'label': '/kaggle/input/scl-chest-ct/masks/12.nrrd'}\n",
      "['Normal', 'Established fibrosis', 'Fine fibrosis/ GGO']\n",
      "tensor([0, 1, 2, 3], dtype=torch.uint8)\n",
      "torch.Size([512, 512, 95])\n",
      "**********\n",
      "{'image': '/kaggle/input/scl-chest-ct/images/13.nii', 'label': '/kaggle/input/scl-chest-ct/masks/13.nrrd'}\n",
      "['Normal', 'Established fibrosis', 'Fine fibrosis/GGO']\n",
      "tensor([0, 1, 4], dtype=torch.uint8)\n",
      "torch.Size([512, 512, 75])\n",
      "**********\n",
      "{'image': '/kaggle/input/scl-chest-ct/images/14.nii', 'label': '/kaggle/input/scl-chest-ct/masks/14.nrrd'}\n",
      "['Normal', 'Established fibrosis', 'Fine fibrosis/GGO']\n",
      "tensor([0, 1, 3, 4], dtype=torch.uint8)\n",
      "torch.Size([512, 512, 179])\n",
      "**********\n",
      "{'image': '/kaggle/input/scl-chest-ct/images/15.nii', 'label': '/kaggle/input/scl-chest-ct/masks/15.nrrd'}\n",
      "['Normal', 'Established fibrosis', 'Fine fibrosis/GGO']\n",
      "tensor([0, 1, 2, 3], dtype=torch.uint8)\n",
      "torch.Size([512, 512, 353])\n",
      "**********\n",
      "{'image': '/kaggle/input/scl-chest-ct/images/16.nii', 'label': '/kaggle/input/scl-chest-ct/masks/16.nrrd'}\n",
      "['Normal', 'Established fibrosis', 'Fine fibrosis/GGO']\n",
      "tensor([0, 1, 4], dtype=torch.uint8)\n",
      "torch.Size([512, 512, 40])\n",
      "**********\n",
      "{'image': '/kaggle/input/scl-chest-ct/images/17.nii', 'label': '/kaggle/input/scl-chest-ct/masks/17.nrrd'}\n",
      "['Normal', 'Esrablished fibrosis', 'Fine fibrosis/GGO']\n",
      "tensor([0, 1, 3, 4], dtype=torch.uint8)\n",
      "torch.Size([512, 512, 95])\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "for subject in dicts:\n",
    "    names = get_names(subject)\n",
    "    sp = preprocessing(subject)\n",
    "    uniques = torch.unique(sp['label'])\n",
    "    print (subject)\n",
    "    print (names)\n",
    "    print (uniques)\n",
    "    print (sp['label'].shape)\n",
    "    print ('*' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed578fed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:15:45.598620Z",
     "iopub.status.busy": "2024-04-03T10:15:45.598210Z",
     "iopub.status.idle": "2024-04-03T10:15:45.604253Z",
     "shell.execute_reply": "2024-04-03T10:15:45.603119Z"
    },
    "papermill": {
     "duration": 0.01827,
     "end_time": "2024-04-03T10:15:45.606396",
     "exception": false,
     "start_time": "2024-04-03T10:15:45.588126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AddChannelDim(MapTransform): #Add a channel dimension for images and one-hot encode\n",
    "  def __call__(self, data):\n",
    "    for key in self.keys:\n",
    "      data[key] = data[key].unsqueeze(0)\n",
    "      # if key == 'image':\n",
    "        # data[key] = torch.cat([data[key],  data[key],  data[key]], dim=0) #since our pretrained model expects inputs with 3 channels\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "999b49f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:15:45.625655Z",
     "iopub.status.busy": "2024-04-03T10:15:45.625228Z",
     "iopub.status.idle": "2024-04-03T10:15:45.629911Z",
     "shell.execute_reply": "2024-04-03T10:15:45.628782Z"
    },
    "papermill": {
     "duration": 0.017056,
     "end_time": "2024-04-03T10:15:45.632240",
     "exception": false,
     "start_time": "2024-04-03T10:15:45.615184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loaded = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e087c4cc",
   "metadata": {
    "papermill": {
     "duration": 0.00803,
     "end_time": "2024-04-03T10:15:45.648901",
     "exception": false,
     "start_time": "2024-04-03T10:15:45.640871",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Subjects 1-8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41b928ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:15:45.666992Z",
     "iopub.status.busy": "2024-04-03T10:15:45.666535Z",
     "iopub.status.idle": "2024-04-03T10:15:45.676750Z",
     "shell.execute_reply": "2024-04-03T10:15:45.675478Z"
    },
    "papermill": {
     "duration": 0.022022,
     "end_time": "2024-04-03T10:15:45.679131",
     "exception": false,
     "start_time": "2024-04-03T10:15:45.657109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LoadNRRD(MapTransform):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__(keys)\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        for key in self.keys:\n",
    "            loaded_tensor = torch.tensor(nrrd.read(data[key])[0])\n",
    "            # Add channel dimension (C, H, W, D)\n",
    "            loaded_tensor = loaded_tensor.unsqueeze(0)\n",
    "            # One-hot encode\n",
    "            one_hot_tensor = torch.zeros((3,) + loaded_tensor.shape[1:])\n",
    "            one_hot_tensor[0] = torch.where(loaded_tensor == 1, torch.tensor(1.0), torch.tensor(0.0))\n",
    "            one_hot_tensor[1] = torch.where(loaded_tensor == 3, torch.tensor(1.0), torch.tensor(0.0))\n",
    "            one_hot_tensor[2] = torch.where((loaded_tensor == 2) | (loaded_tensor == 4), torch.tensor(1.0), torch.tensor(0.0))\n",
    "            data[key] = one_hot_tensor.to(torch.float32)\n",
    "#             print(data[key].shape)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcfd0418",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:15:45.698270Z",
     "iopub.status.busy": "2024-04-03T10:15:45.697868Z",
     "iopub.status.idle": "2024-04-03T10:15:45.708073Z",
     "shell.execute_reply": "2024-04-03T10:15:45.707054Z"
    },
    "papermill": {
     "duration": 0.022873,
     "end_time": "2024-04-03T10:15:45.710396",
     "exception": false,
     "start_time": "2024-04-03T10:15:45.687523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessing = Compose([\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        AddChannelDim(keys=['image']),\n",
    "        LoadNRRD(keys=['label']),\n",
    "#         CropForegroundd(keys=['image', 'label'], source_key='image'),\n",
    "        Resized(keys=['image', 'label'], spatial_size=(128, 128, 64), mode=['trilinear', 'nearest-exact']),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47bdbdc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:15:45.728499Z",
     "iopub.status.busy": "2024-04-03T10:15:45.728118Z",
     "iopub.status.idle": "2024-04-03T10:15:59.152169Z",
     "shell.execute_reply": "2024-04-03T10:15:59.151043Z"
    },
    "papermill": {
     "duration": 13.436087,
     "end_time": "2024-04-03T10:15:59.154807",
     "exception": false,
     "start_time": "2024-04-03T10:15:45.718720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexes = [1,2,3,4,5,7,8]\n",
    "subjects = []\n",
    "for index in indexes:\n",
    "  subjects.append({\n",
    "      'image': f'/kaggle/input/scl-chest-ct/images/{index}.nii',\n",
    "      'label': f'/kaggle/input/scl-chest-ct/masks/{index}.nrrd'\n",
    "  })\n",
    "loaded.extend(preprocessing(subjects))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba2a60e",
   "metadata": {
    "papermill": {
     "duration": 0.007801,
     "end_time": "2024-04-03T10:15:59.170944",
     "exception": false,
     "start_time": "2024-04-03T10:15:59.163143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Subjects 11, 14, 17\n",
    "* 11, 14, 17: 1, 3, 4\n",
    "* 9, 10, 13, 16: 1, 4\n",
    "* 12, 15: 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26e74750",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:15:59.189483Z",
     "iopub.status.busy": "2024-04-03T10:15:59.188435Z",
     "iopub.status.idle": "2024-04-03T10:15:59.196858Z",
     "shell.execute_reply": "2024-04-03T10:15:59.195890Z"
    },
    "papermill": {
     "duration": 0.020144,
     "end_time": "2024-04-03T10:15:59.199102",
     "exception": false,
     "start_time": "2024-04-03T10:15:59.178958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LoadNRRD(MapTransform):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__(keys)\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        for key in self.keys:\n",
    "            loaded_tensor = torch.tensor(nrrd.read(data[key])[0])\n",
    "            # Add channel dimension (C, H, W, D)\n",
    "            loaded_tensor = loaded_tensor.unsqueeze(0)\n",
    "            # One-hot encode\n",
    "            one_hot_tensor = torch.zeros((3,) + loaded_tensor.shape[1:])\n",
    "            one_hot_tensor[0] = torch.where(loaded_tensor == 1, torch.tensor(1.0), torch.tensor(0.0))\n",
    "            one_hot_tensor[1] = torch.where(loaded_tensor == 3, torch.tensor(1.0), torch.tensor(0.0))\n",
    "            one_hot_tensor[2] = torch.where(loaded_tensor == 4, torch.tensor(1.0), torch.tensor(0.0))\n",
    "            data[key] = one_hot_tensor.to(torch.float32)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fca5a972",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:15:59.216977Z",
     "iopub.status.busy": "2024-04-03T10:15:59.216586Z",
     "iopub.status.idle": "2024-04-03T10:16:05.245980Z",
     "shell.execute_reply": "2024-04-03T10:16:05.244796Z"
    },
    "papermill": {
     "duration": 6.041502,
     "end_time": "2024-04-03T10:16:05.248705",
     "exception": false,
     "start_time": "2024-04-03T10:15:59.207203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessing = Compose([\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        AddChannelDim(keys=['image']),\n",
    "        LoadNRRD(keys=['label']),\n",
    "#         CropForegroundd(keys=['image', 'label'], source_key='image'),\n",
    "        Resized(keys=['image', 'label'], spatial_size=(128, 128, 64), mode=['trilinear', 'nearest-exact']),\n",
    "    ])\n",
    "indexes = [11, 14, 17]\n",
    "subjects = []\n",
    "for index in indexes:\n",
    "  subjects.append({\n",
    "      'image': f'/kaggle/input/scl-chest-ct/images/{index}.nii',\n",
    "      'label': f'/kaggle/input/scl-chest-ct/masks/{index}.nrrd'\n",
    "  })\n",
    "loaded.extend(preprocessing(subjects))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f841cf3",
   "metadata": {
    "papermill": {
     "duration": 0.008232,
     "end_time": "2024-04-03T10:16:05.265240",
     "exception": false,
     "start_time": "2024-04-03T10:16:05.257008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Subjects 9, 10, 13\n",
    "* 11, 14, 17: 1, 3, 4\n",
    "* 9, 10, 13, 16: 1, 4\n",
    "* 12, 15: 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6312c324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:16:05.283274Z",
     "iopub.status.busy": "2024-04-03T10:16:05.282875Z",
     "iopub.status.idle": "2024-04-03T10:16:05.290597Z",
     "shell.execute_reply": "2024-04-03T10:16:05.289614Z"
    },
    "papermill": {
     "duration": 0.019759,
     "end_time": "2024-04-03T10:16:05.293097",
     "exception": false,
     "start_time": "2024-04-03T10:16:05.273338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LoadNRRD(MapTransform):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__(keys)\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        for key in self.keys:\n",
    "            loaded_tensor = torch.tensor(nrrd.read(data[key])[0])\n",
    "            # Add channel dimension (C, H, W, D)\n",
    "            loaded_tensor = loaded_tensor.unsqueeze(0)\n",
    "            # One-hot encode\n",
    "            one_hot_tensor = torch.zeros((3,) + loaded_tensor.shape[1:])\n",
    "            one_hot_tensor[0] = torch.where(loaded_tensor == 1, torch.tensor(1.0), torch.tensor(0.0))\n",
    "            one_hot_tensor[1] = torch.where(loaded_tensor == 3, torch.tensor(1.0), torch.tensor(0.0))\n",
    "            one_hot_tensor[2] = torch.where(loaded_tensor == 4, torch.tensor(1.0), torch.tensor(0.0))\n",
    "            data[key] = one_hot_tensor.to(torch.float32)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e88778c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:16:05.311305Z",
     "iopub.status.busy": "2024-04-03T10:16:05.310664Z",
     "iopub.status.idle": "2024-04-03T10:16:17.833520Z",
     "shell.execute_reply": "2024-04-03T10:16:17.827871Z"
    },
    "papermill": {
     "duration": 12.547421,
     "end_time": "2024-04-03T10:16:17.848689",
     "exception": false,
     "start_time": "2024-04-03T10:16:05.301268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessing = Compose([\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        AddChannelDim(keys=['image']),\n",
    "        LoadNRRD(keys=['label']),\n",
    "#         CropForegroundd(keys=['image', 'label'], source_key='image'),\n",
    "        Resized(keys=['image', 'label'], spatial_size=(128, 128, 64), mode=['trilinear', 'nearest-exact']), #expected efficientNetv2 size\n",
    "\n",
    "    ])\n",
    "indexes = [9, 10, 13, 16]\n",
    "subjects = []\n",
    "for index in indexes:\n",
    "  subjects.append({\n",
    "      'image': f'/kaggle/input/scl-chest-ct/images/{index}.nii',\n",
    "      'label': f'/kaggle/input/scl-chest-ct/masks/{index}.nrrd'\n",
    "  })\n",
    "loaded.extend(preprocessing(subjects))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e83dad",
   "metadata": {
    "papermill": {
     "duration": 0.028303,
     "end_time": "2024-04-03T10:16:17.912003",
     "exception": false,
     "start_time": "2024-04-03T10:16:17.883700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Subjects 12, 15\n",
    "* 11, 14, 17: 1, 3, 4\n",
    "* 9, 10, 13, 16: 1, 4\n",
    "* 12, 15: 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3c5a127",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:16:17.974901Z",
     "iopub.status.busy": "2024-04-03T10:16:17.972824Z",
     "iopub.status.idle": "2024-04-03T10:16:17.994943Z",
     "shell.execute_reply": "2024-04-03T10:16:17.991518Z"
    },
    "papermill": {
     "duration": 0.064814,
     "end_time": "2024-04-03T10:16:18.003757",
     "exception": false,
     "start_time": "2024-04-03T10:16:17.938943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LoadNRRD(MapTransform):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__(keys)\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        for key in self.keys:\n",
    "            loaded_tensor = torch.tensor(nrrd.read(data[key])[0])\n",
    "            # Add channel dimension (C, H, W, D)\n",
    "            loaded_tensor = loaded_tensor.unsqueeze(0)\n",
    "            # One-hot encode\n",
    "            one_hot_tensor = torch.zeros((3,) + loaded_tensor.shape[1:])\n",
    "            one_hot_tensor[0] = torch.where(loaded_tensor == 1, torch.tensor(1.0), torch.tensor(0.0))\n",
    "            one_hot_tensor[1] = torch.where(loaded_tensor == 2, torch.tensor(1.0), torch.tensor(0.0))\n",
    "            one_hot_tensor[2] = torch.where(loaded_tensor == 3, torch.tensor(1.0), torch.tensor(0.0))\n",
    "            data[key] = one_hot_tensor.to(torch.float32)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e201cffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:16:18.063687Z",
     "iopub.status.busy": "2024-04-03T10:16:18.062136Z",
     "iopub.status.idle": "2024-04-03T10:16:33.533453Z",
     "shell.execute_reply": "2024-04-03T10:16:33.532032Z"
    },
    "papermill": {
     "duration": 15.502832,
     "end_time": "2024-04-03T10:16:33.536875",
     "exception": false,
     "start_time": "2024-04-03T10:16:18.034043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessing = Compose([\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        AddChannelDim(keys=['image']),\n",
    "        LoadNRRD(keys=['label']),\n",
    "#         CropForegroundd(keys=['image', 'label'], source_key='image'),\n",
    "        Resized(keys=['image', 'label'], spatial_size=(128, 128, 64), mode=['trilinear', 'nearest-exact']), #expected efficientNetv2 size\n",
    "\n",
    "    ])\n",
    "indexes = [12, 15]\n",
    "subjects = []\n",
    "for index in indexes:\n",
    "  subjects.append({\n",
    "      'image': f'/kaggle/input/scl-chest-ct/images/{index}.nii',\n",
    "      'label': f'/kaggle/input/scl-chest-ct/masks/{index}.nrrd'\n",
    "  })\n",
    "loaded.extend(preprocessing(subjects))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f8b4f",
   "metadata": {
    "papermill": {
     "duration": 0.007797,
     "end_time": "2024-04-03T10:16:33.553981",
     "exception": false,
     "start_time": "2024-04-03T10:16:33.546184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Subject 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01ba0a6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:16:33.572864Z",
     "iopub.status.busy": "2024-04-03T10:16:33.571752Z",
     "iopub.status.idle": "2024-04-03T10:16:33.580240Z",
     "shell.execute_reply": "2024-04-03T10:16:33.579057Z"
    },
    "papermill": {
     "duration": 0.020801,
     "end_time": "2024-04-03T10:16:33.582817",
     "exception": false,
     "start_time": "2024-04-03T10:16:33.562016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LoadNRRD(MapTransform):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__(keys)\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        for key in self.keys:\n",
    "            loaded_tensor = torch.tensor(nrrd.read(data[key])[0])\n",
    "            # Add channel dimension (C, H, W, D)\n",
    "            loaded_tensor = loaded_tensor\n",
    "            # One-hot encode\n",
    "            one_hot_tensor = torch.zeros((3,) + loaded_tensor.shape[1:])\n",
    "            one_hot_tensor[0] = loaded_tensor[0, :, :, :]\n",
    "            one_hot_tensor[1] = torch.zeros_like(loaded_tensor[0, :, :, :])\n",
    "            one_hot_tensor[2] = loaded_tensor[1, :, :, :]\n",
    "            data[key] = one_hot_tensor.to(torch.float32)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99f15b22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:16:33.603577Z",
     "iopub.status.busy": "2024-04-03T10:16:33.600889Z",
     "iopub.status.idle": "2024-04-03T10:16:34.890928Z",
     "shell.execute_reply": "2024-04-03T10:16:34.889701Z"
    },
    "papermill": {
     "duration": 1.302473,
     "end_time": "2024-04-03T10:16:34.893448",
     "exception": false,
     "start_time": "2024-04-03T10:16:33.590975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessing = Compose([\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        AddChannelDim(keys=['image']),\n",
    "        LoadNRRD(keys=['label']),\n",
    "#         CropForegroundd(keys=['image', 'label'], source_key='image'),\n",
    "        Resized(keys=['image', 'label'], spatial_size=(128, 128, 64), mode=['trilinear', 'nearest-exact']), #expected efficientNetv2 size\n",
    "\n",
    "    ])\n",
    "indexes = [6]\n",
    "subjects = []\n",
    "for index in indexes:\n",
    "  subjects.append({\n",
    "      'image': f'/kaggle/input/scl-chest-ct/images/{index}.nii',\n",
    "      'label': f'/kaggle/input/scl-chest-ct/masks/{index}.nrrd'\n",
    "  })\n",
    "loaded.extend(preprocessing(subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50ccc0ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:16:34.911893Z",
     "iopub.status.busy": "2024-04-03T10:16:34.911503Z",
     "iopub.status.idle": "2024-04-03T10:16:34.921606Z",
     "shell.execute_reply": "2024-04-03T10:16:34.920613Z"
    },
    "papermill": {
     "duration": 0.022209,
     "end_time": "2024-04-03T10:16:34.924040",
     "exception": false,
     "start_time": "2024-04-03T10:16:34.901831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9218ef5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T10:16:34.942307Z",
     "iopub.status.busy": "2024-04-03T10:16:34.941906Z",
     "iopub.status.idle": "2024-04-03T10:16:35.439354Z",
     "shell.execute_reply": "2024-04-03T10:16:35.438313Z"
    },
    "papermill": {
     "duration": 0.510005,
     "end_time": "2024-04-03T10:16:35.442307",
     "exception": false,
     "start_time": "2024-04-03T10:16:34.932302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('dataset.pkl', \"wb\") as file:\n",
    "    pkl.dump(loaded, file)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4681126,
     "sourceId": 7958105,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 190.172148,
   "end_time": "2024-04-03T10:16:38.741469",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-03T10:13:28.569321",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
